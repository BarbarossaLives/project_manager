#!/usr/bin/env python3
"""
Setup script for Ollama AI integration
This script helps users set up Ollama for AI-powered project planning
"""

import subprocess
import sys
import requests
import time
import platform

def check_ollama_installed():
    """Check if Ollama is installed"""
    try:
        result = subprocess.run(['ollama', '--version'], capture_output=True, text=True)
        return result.returncode == 0
    except FileNotFoundError:
        return False

def install_ollama():
    """Install Ollama based on the operating system"""
    system = platform.system().lower()
    
    print("ü§ñ Installing Ollama...")
    
    if system == "linux" or system == "darwin":  # Linux or macOS
        try:
            # Download and run the install script
            subprocess.run(['curl', '-fsSL', 'https://ollama.ai/install.sh'], check=True)
            print("‚úÖ Ollama installation script downloaded")
            subprocess.run(['sh', '-c', 'curl -fsSL https://ollama.ai/install.sh | sh'], check=True)
            print("‚úÖ Ollama installed successfully")
        except subprocess.CalledProcessError as e:
            print(f"‚ùå Failed to install Ollama: {e}")
            print("Please visit https://ollama.ai for manual installation instructions")
            return False
    
    elif system == "windows":
        print("ü™ü For Windows, please:")
        print("1. Visit https://ollama.ai")
        print("2. Download the Windows installer")
        print("3. Run the installer")
        print("4. Restart this script after installation")
        return False
    
    else:
        print(f"‚ùå Unsupported operating system: {system}")
        print("Please visit https://ollama.ai for installation instructions")
        return False
    
    return True

def check_ollama_running():
    """Check if Ollama service is running"""
    try:
        response = requests.get("http://localhost:11434/api/tags", timeout=5)
        return response.status_code == 200
    except:
        return False

def start_ollama():
    """Start Ollama service"""
    print("üöÄ Starting Ollama service...")
    try:
        # Start Ollama in the background
        subprocess.Popen(['ollama', 'serve'], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
        
        # Wait for service to start
        for i in range(30):  # Wait up to 30 seconds
            if check_ollama_running():
                print("‚úÖ Ollama service started successfully")
                return True
            time.sleep(1)
            print(f"‚è≥ Waiting for Ollama to start... ({i+1}/30)")
        
        print("‚ùå Ollama service failed to start within 30 seconds")
        return False
        
    except Exception as e:
        print(f"‚ùå Failed to start Ollama: {e}")
        return False

def pull_model(model_name="llama3.2"):
    """Pull the specified model"""
    print(f"üì• Pulling {model_name} model...")
    print("‚ö†Ô∏è  This may take several minutes depending on your internet connection")
    
    try:
        result = subprocess.run(['ollama', 'pull', model_name], check=True)
        print(f"‚úÖ {model_name} model downloaded successfully")
        return True
    except subprocess.CalledProcessError as e:
        print(f"‚ùå Failed to pull {model_name} model: {e}")
        return False

def test_ai_integration():
    """Test the AI integration"""
    print("üß™ Testing AI integration...")
    
    try:
        from ai import ollama_ai
        
        if not ollama_ai.is_available():
            print("‚ùå Ollama is not available")
            return False
        
        # Test a simple prompt
        response = ollama_ai.generate_response("Say 'Hello from Ollama!' in exactly those words.")
        
        if response and "Hello from Ollama!" in response:
            print("‚úÖ AI integration test passed")
            print(f"ü§ñ AI Response: {response}")
            return True
        else:
            print("‚ö†Ô∏è  AI integration test partially successful")
            print(f"ü§ñ AI Response: {response}")
            return True
            
    except Exception as e:
        print(f"‚ùå AI integration test failed: {e}")
        return False

def main():
    """Main setup function"""
    print("üöÄ Setting up Ollama AI Integration for Project Manager")
    print("=" * 60)
    
    # Check if Ollama is installed
    if not check_ollama_installed():
        print("‚ùå Ollama is not installed")
        if not install_ollama():
            print("‚ùå Setup failed. Please install Ollama manually and run this script again.")
            return False
    else:
        print("‚úÖ Ollama is already installed")
    
    # Check if Ollama is running
    if not check_ollama_running():
        print("‚ùå Ollama service is not running")
        if not start_ollama():
            print("‚ùå Failed to start Ollama service")
            print("üí° Try running 'ollama serve' manually in another terminal")
            return False
    else:
        print("‚úÖ Ollama service is running")
    
    # Pull the model
    if not pull_model():
        print("‚ùå Failed to download AI model")
        return False
    
    # Test integration
    if not test_ai_integration():
        print("‚ùå AI integration test failed")
        return False
    
    print("\nüéâ Setup completed successfully!")
    print("\nüìã What you can do now:")
    print("‚Ä¢ Create AI-powered project plans")
    print("‚Ä¢ Get intelligent project analysis")
    print("‚Ä¢ Auto-adjust schedules based on progress")
    print("‚Ä¢ Break down complex tasks into subtasks")
    print("\nüöÄ Start your project manager and try the AI features!")
    
    return True

if __name__ == "__main__":
    try:
        success = main()
        sys.exit(0 if success else 1)
    except KeyboardInterrupt:
        print("\n‚ùå Setup interrupted by user")
        sys.exit(1)
    except Exception as e:
        print(f"\n‚ùå Unexpected error: {e}")
        sys.exit(1)
